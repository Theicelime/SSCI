import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import time

# --- 1. é«˜çº§ UI æ ·å¼å®šä¹‰ (çœŸæ­£çš„åº”ç”¨æ„Ÿ) ---
def apply_premium_style():
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Noto+Sans+SC:wght@300;500;900&display=swap');
    
    :root {
        --primary: #2563eb;
        --bg-main: #f8fafc;
        --card-bg: rgba(255, 255, 255, 0.8);
    }

    .stApp { background-color: var(--bg-main); }
    
    /* æè‡´å¡ç‰‡è®¾è®¡ */
    .paper-card {
        background: var(--card-bg);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 20px;
        padding: 24px;
        margin-bottom: 20px;
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.05);
        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
    }
    
    .paper-card:hover {
        transform: translateY(-5px) scale(1.01);
        box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
        border-color: var(--primary);
    }

    /* åˆŠåä¸æ ‡ç­¾ */
    .journal-tag {
        font-family: 'JetBrains Mono', monospace;
        font-size: 11px;
        font-weight: 700;
        background: #dbeafe;
        color: #1e40af;
        padding: 4px 10px;
        border-radius: 6px;
        margin-bottom: 12px;
        display: inline-block;
    }

    .paper-title {
        font-family: 'Noto Sans SC', sans-serif;
        font-size: 1.2rem;
        font-weight: 900;
        color: #0f172a;
        line-height: 1.4;
        margin-bottom: 12px;
    }

    .ai-summary-box {
        background: #f1f5f9;
        border-left: 4px solid var(--primary);
        padding: 12px;
        border-radius: 8px;
        font-size: 13px;
        color: #475569;
        margin: 15px 0;
    }

    /* çŠ¶æ€æ  */
    .meta-footer {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-top: 20px;
        font-size: 12px;
        color: #94a3b8;
    }
    
    /* éšè— Streamlit åŸç”Ÿå…ƒç´  */
    div[data-testid="stToolbar"] { visibility: hidden; }
    footer { visibility: hidden; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. æ·±åº¦æ•°æ®å¼•æ“ ---
@st.cache_data(ttl=3600)
def get_intel_data(keywords, journal_ids, limit=25):
    """
    é‡‡ç”¨åŒé‡æ£€ç´¢ï¼šå…³é”®è¯ç²¾ç¡®åŒ¹é… + æ ¸å¿ƒæœŸåˆŠè¿½è¸ª
    """
    # å…³é”®è¯éƒ¨åˆ†
    query = f"(abstract.search:\"{keywords}\" OR title.search:\"{keywords}\")"
    
    # æœŸåˆŠè¿‡æ»¤éƒ¨åˆ†
    if journal_ids:
        journal_filter = "primary_location.schema_id:" + "|".join(journal_ids)
        full_filter = f"{query},{journal_filter}"
    else:
        full_filter = query

    url = f"https://api.openalex.org/works?filter={full_filter}&sort=publication_date:desc&per_page={limit}"
    
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            return r.json().get('results', [])
        return []
    except Exception as e:
        return []

def decode_abstract(inverted):
    if not inverted: return "Abstract not provided by publisher."
    idx = []
    for word, positions in inverted.items():
        for p in positions: idx.append((p, word))
    idx.sort()
    full_text = " ".join([x[1] for x in idx])
    return full_text[:400] + "..."

# --- 3. AI æ™ºèƒ½æ€»ç»“é€»è¾‘ ---
def get_ai_insight(text, api_key):
    """
    è°ƒç”¨ AI æ¥å£è¿›è¡Œè®ºæ–‡æ´å¯Ÿ
    """
    if not api_key: return "è¯·åœ¨ä¾§è¾¹æ é…ç½® API Key ä»¥å¼€å¯ AI æ´å¯Ÿã€‚"
    
    # è¿™é‡Œä»¥ DeepSeek ä¸ºä¾‹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦åˆ‡æ¢
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è€é¾„ç¯å¢ƒå­¦ä¸“å®¶ï¼Œè¯·ç”¨ä¸­æ–‡ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ‘˜è¦çš„æ ¸å¿ƒç ”ç©¶è´¡çŒ®ï¼š"},
            {"role": "user", "content": text}
        ]
    }
    try:
        # æ¨¡æ‹Ÿè°ƒç”¨æˆ–å®é™…è°ƒç”¨ (æ­¤å¤„ä¸ºå ä½ï¼Œå®é™…ä½¿ç”¨æ—¶å–æ¶ˆæ³¨é‡Š)
        # res = requests.post("https://api.deepseek.com/v1/chat/completions", json=payload, headers=headers)
        # return res.json()['choices'][0]['message']['content']
        return "âœ¨ æ¨¡æ‹Ÿæ´å¯Ÿï¼šè¯¥ç ”ç©¶é€šè¿‡å®è¯åˆ†ææ¢è®¨äº†åŸå¸‚ç»¿åœ°å¯¹å¤±æ™ºè€äººç”Ÿæ´»è´¨é‡çš„æ­£å‘å½±å“ï¼Œæå‡ºäº†ç¯å¢ƒå¼¹æ€§è¡¥å¿æ¨¡å‹ã€‚"
    except:
        return "AI æœåŠ¡æš‚æ—¶å¿™ç¢Œ..."

# --- 4. ä¸»ç¨‹åºç•Œé¢ ---
def main():
    apply_premium_style()
    
    # --- Sidebar: ä¸“å®¶æ§åˆ¶é¢æ¿ ---
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2103/2103633.png", width=60)
        st.title("æ™ºåº“æ§åˆ¶å°")
        st.markdown("---")
        
        journals = {
            "The Gerontologist": "S4306399625",
            "Health & Place": "S108842106",
            "Landscape & Urban Planning": "S162319083",
            "Age and Ageing": "S169624507",
            "J. of Env Psychology": "S156885347"
        }
        
        st.subheader("ğŸ“¡ é¢‘é“è®¢é˜…")
        selected_journals = st.multiselect("æ ¸å¿ƒåˆŠç‰©", list(journals.keys()), default=list(journals.keys())[:3])
        ids = [journals[k] for k in selected_journals]
        
        st.subheader("ğŸ” ç²¾å‡†ç”»åƒ")
        keywords = st.text_input("å­¦æœ¯å…³é”®è¯", value="environmental gerontology")
        
        st.subheader("ğŸ¤– AI ç¥ç»å…ƒ")
        ai_on = st.toggle("å¼€å¯ AI æ·±åº¦è§£æ", value=True)
        key = st.sidebar.text_input("API Key", type="password", help="æ”¯æŒ DeepSeek/OpenAI æ ¼å¼")
        
        st.markdown("---")
        st.caption("Gerontology Intel v3.0 Pro\nPowered by OpenAlex & DeepSeek")

    # --- Main Canvas ---
    st.markdown(f"### ğŸŒ å…¨çƒè€é¾„ç¯å¢ƒç ”ç©¶Â·å®æ—¶æƒ…æŠ¥")
    st.caption(f"æ£€ç´¢åˆ°æ¥è‡ª {len(selected_journals)} ä¸ªé¡¶åˆŠçš„æœ€æ–°æ•°æ® | å½“å‰æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")

    # æ•°æ®åŠ è½½çŠ¶æ€
    with st.spinner("æ­£åœ¨ç©¿é€å­¦æœ¯å£å’..."):
        papers = get_intel_data(keywords, ids)

    if not papers:
        st.error("âŒ æœªèƒ½åœ¨å½“å‰é¢‘é“ä¸‹å‘ç°è®ºæ–‡ã€‚å°è¯•æ‰©å¤§æœç´¢å…³é”®è¯æˆ–å¢åŠ è®¢é˜…æœŸåˆŠã€‚")
        return

    # å†…å®¹å±•ç¤º (Pinterest é£æ ¼æ …æ ¼)
    col1, col2 = st.columns(2, gap="large")
    
    for i, paper in enumerate(papers):
        target_col = col1 if i % 2 == 0 else col2
        
        title = paper.get('display_name', 'Untitled')
        journal = paper.get('host_venue', {}).get('display_name', 'Unknown Source')
        date = paper.get('publication_date', 'N/A')
        citations = paper.get('cited_by_count', 0)
        abstract = decode_abstract(paper.get('abstract_inverted_index'))
        doi = paper.get('doi', '#')

        with target_col:
            st.markdown(f"""
            <div class="paper-card">
                <div class="journal-tag">{journal}</div>
                <div class="paper-title">{title}</div>
                <div class="abstract-preview">{abstract[:180]}...</div>
                <div class="meta-footer">
                    <span>ğŸ“… {date}</span>
                    <span>ğŸ”¥ å¼•ç”¨: {citations}</span>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # å¡ç‰‡äº¤äº’åŒº
            exp = st.expander("å±•å¼€æ·±åº¦æƒ…æŠ¥")
            with exp:
                if ai_on:
                    st.markdown(f"**ğŸ¤– AI æ ¸å¿ƒæ´å¯Ÿ:**")
                    st.info(get_ai_insight(abstract, key))
                
                st.markdown(f"**æ‘˜è¦å…¨æ–‡:**\n\n{abstract}")
                st.link_button("ğŸš€ æŸ¥çœ‹åŸåˆŠè®ºæ–‡", doi, use_container_width=True)
            
            st.markdown("<div style='height:15px'></div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
